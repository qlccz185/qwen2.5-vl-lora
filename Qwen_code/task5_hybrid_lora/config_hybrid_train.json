{
  "working_dir": "/root/autodl-tmp/qwen2.5-vl-lora/Qwen_code",
  "base_model_path": "/root/autodl-tmp/Qwen2.5-VL-7B-Instruct",
  "data_root": "/root/autodl-tmp/data",
  "ann_train": "/root/autodl-tmp/data/trainingset2/train_idx.json",
  "output_dir": "/root/autodl-tmp/task5_hybrid_lora/training",
  "frozen_head_path": "/root/autodl-tmp/qwen2.5-vl-lora/Qwen_pretrain/head/best_by_AUROC_joint_lora.pt",
  "visual_lora": {
    "path": "/root/autodl-tmp/qwen2.5-vl-lora/Qwen_pretrain/lora_adapter",
    "layers": [7, 15, 23, 31]
  },

  "seed": 42,
  "epochs": 2,
  "batch_size": 2,
  "num_workers": 4,
  "grad_accum": 1,

  "lr_lora": 0.0001,
  "lr_fusion": 0.0005,
  "weight_decay": 0.01,
  "warmup_ratio": 0.05,
  "max_norm": 1.0,

  "amp_dtype": "bf16",
  "torch_dtype": "bfloat16",
  "image_size": 448,

  "visual_layers": [7, 15, 23, 31],
  "fusion_tokens": 4,
  "fusion_hidden_dropout": 0.1,

  "target_text": {
    "fake": "Fake",
    "real": "Real"
  },

  "loss_weights": {
    "lm": 1.0,
    "head_cls": 1.0,
    "head_evi": 2.0,
    "head_sparse": 0.001,
    "head_contrast": 0.01
  },

  "lora": {
    "r": 8,
    "alpha": 16,
    "dropout": 0.05,
    "bias": "none",
    "lm": {
      "enabled": true,
      "extra_modules": [
        "language_model.layers.24.self_attn.q_proj",
        "language_model.layers.24.self_attn.v_proj",
        "language_model.layers.25.self_attn.q_proj",
        "language_model.layers.25.self_attn.v_proj",
        "language_model.layers.26.self_attn.q_proj",
        "language_model.layers.26.self_attn.v_proj",
        "language_model.layers.27.self_attn.q_proj",
        "language_model.layers.27.self_attn.v_proj"
      ]
    }
  },

  "train_log": "task5_training_metrics.csv",
  "lora_checkpoint": "task5_lora",
  "head_snapshot": "task5_frozen_head.pt",
  "fusion_checkpoint": "task5_fusion.pt"
}
