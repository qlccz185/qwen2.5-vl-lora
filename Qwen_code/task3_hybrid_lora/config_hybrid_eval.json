{
  "working_dir": "/root/autodl-tmp/qwen2.5-vl-lora/Qwen_code",
  "base_model_path": "/root/autodl-tmp/Qwen2.5-VL-7B-Instruct",
  "data_root": "/root/autodl-tmp/data",
  "ann_eval": "/root/autodl-tmp/data/testset2/annotation.json",

  "seed": 42,
  "batch_size": 2,
  "num_workers": 4,
  "torch_dtype": "bfloat16",
  "image_size": 448,

  "visual_layers": [7, 15, 23, 31],
  "fusion_tokens": 4,
  "fusion_hidden_dropout": 0.1,

  "target_text": {
    "fake": "Fake",
    "real": "Real"
  },

  "lora": {
    "r": 8,
    "alpha": 16,
    "dropout": 0.05,
    "bias": "none",
    "visual": {
      "enabled": true,
      "blocks": [7, 15, 23, 31],
      "extra_patterns": ["visual.proj", "visual.attn"]
    },
    "lm": {
      "enabled": true,
      "extra_modules": [
        "language_model.layers.24.self_attn.q_proj",
        "language_model.layers.24.self_attn.v_proj",
        "language_model.layers.25.self_attn.q_proj",
        "language_model.layers.25.self_attn.v_proj",
        "language_model.layers.26.self_attn.q_proj",
        "language_model.layers.26.self_attn.v_proj",
        "language_model.layers.27.self_attn.q_proj",
        "language_model.layers.27.self_attn.v_proj"
      ]
    }
  },

  "lora_checkpoint": "/root/autodl-tmp/task3_hybrid_lora/training/task3_lora/adapter_model.safetensors",
  "head_checkpoint": "/root/autodl-tmp/task3_hybrid_lora/training/task3_heads.pt",
  "fusion_checkpoint": "/root/autodl-tmp/task3_hybrid_lora/training/task3_fusion.pt",

  "metrics_csv": "/root/autodl-tmp/task3_hybrid_lora/eval/task3_eval_metrics.csv",
  "inference_output": "/root/autodl-tmp/task3_hybrid_lora/eval/task3_inference_results.json"
}
